---
title: "Explanatory data analysis with PCA. Decathlon data analysis"
author: "Julie Josse"
date: "24/10/2018"
output:
  html_document: default
  pdf_document: default
---

#  Principal Component Analysis

## Lecture questions

1) When do we need to scale the variables? Simulate and comment:
```{r eval = FALSE}
library(mvtnorm)
Z <- rmvnorm(n = 200, rep(0, 3), sigma = diag(3))
X1 <- Z[, 1]
X2 <- X1 + 0.001*Z[, 2]
X3 <- 10*Z[, 3]
don <- cbind.data.frame(X1, X2, X3)

library(FactoMineR)
res.pca <- PCA(don, scale = F)
res.pcascaled <- PCA(don, scale = T)
```


2) TRUE or FALSE. If you perform a standardized PCA on a huge number of variables: the percentage of variability of the two first dimensions is small.



3) A scaled PCA has been performed on 4 data sets. Link correlation matrices and PCA results.

```{r, echo = FALSE, out.width= '75%', fig.align='center', eval=TRUE}
knitr::include_graphics("fig/PCA_cor.png")
```

The value of the first eigenvalue approximately gives the number of correlated variables explained by the first dimension.


4) What is the percentage of variability of the first dimension? The first plane?

```{r, echo = FALSE, out.width= '50%', fig.align='center', eval = TRUE}
knitr::include_graphics("fig/AnaDo_ACP_exo_Graphe_var2.jpg")
```


5) We have a data table with 4 rows and 10 independent variables. Without performing the PCA, do we have an idea of the shape of the correlation circle obtained? Simulate and comment. (You can increase the number of rows, also look at cases with 10 rows and 2000 variables, etc..)


```{r pca, echo = TRUE, eval = TRUE}

```

6) Write a program to obtain the tables of the lecture slides. "Percentage of variability under the null".  

```{r include = TRUE}

```


## PCA on decathlon data

```{r import-load, results='hide'}
# Install the package
#install.packages("FactoMineR", dependencies = TRUE)
# Load the package
library(FactoMineR)
data(decathlon)
head(decathlon)
```

This dataset contains the results of decathlon events during two athletic meetings which took place one month apart in 2004: the Olympic Games in Athens (23 and 24 August), and the Decastar 2004 (25 and 26 September). For both competitions, the following information is available for each athlete: performance for each of the 10 events, total number of points (for each
event, an athlete earns points based on performance; here the sum of points
scored) and final ranking. The events took place in the following order: 100 meters, long jump, shot put, high jump, 400 meters (first day) and 110 meter hurdles, discus, pole vault, javelin, 1500 meters (second
day). Nine athletes participated to both competitions. We would like to obtain a typology of the performance profiles.

1) You should inspect the data set with the following commands:
```{r dim, eval=FALSE}
summary(decathlon)
dim(decathlon)
#View(decathlon)
#?decathlon
rownames(decathlon)
```

2) Explain the interest of centering and scaling the data. Could you spotlight outstanding athletes ? Which inequality are you using?

The aim of conducting PCA on this dataset is to determine profiles for similar performances: are there any athletes who are
better at endurance events or those requiring short bursts of energy, etc? And are some of the events similar? If an athlete performs well in one event, will he necessarily perform well in another?

3) Explain your choices for the active and illustrative variables/individuals and perform the PCA on this data set.

```{r, eval = FALSE, include = TRUE}
 
```


4) Comment the percentage of variability explained by the two first dimensions. What would you like (a small percentage, a high percentage) and why?


5) Comment: 
- the correlation between the 100 m and long.jump
- the correlation between long.jump and Pole.vault
- can you describe the athlete Casarsa? 
- the proximity between Sebrle and Clay 
- the proximity between Schoenbeck and Barras


```{r, echo = TRUE, eval = FALSE}

```

6) Enhance the graphical outputs with the following options:
```{r eval = FALSE}
 plot.PCA(res.pca, choix = "ind", habillage = ncol(decathlon), cex = 0.7)
 plot.PCA(res.pca, choix = "ind", habillage = ncol(decathlon), cex = 0.7, 
 autolab = "no")
 plot(res.pca, select = "cos2 0.8",  invisible = "quali")
 plot(res.pca, select = "contrib 10")
 plot(res.pca, choix = "var", select = "contrib 8", unselect = 0)
 plot(res.pca, choix = "var", select = c("400m", "1500m"))
```

7) In which trials those who win the decathlon perform the best? Could we say that the decathlon trials are well selected? 

8) Compare and comment the performances during both events: Decastar and Olympic. Could we conclude on the differences?  Perform a test or plot Confidence ellipses:

```{r eval = FALSE}
dimdesc(res.pca)
dimdesc(res.pca, proba = 0.2) 
plotellipses(res.pca)
```


9) To select the number of dimensions, you should have a look at 
```{r eval = FALSE}
?estim_ncp
```
which performs cross validation as detailed in the lecture slides.

## Other application to practice

### Chicken microarray data and  fatty acid concentration

This is an experiment with 27 chickens with six diet conditions: normal diet (N), fasting for 16 hours (F16), fasting for 16 hours then refed for 5 hours (F16R5), fasting
for 16 hours then refed for 16 hours (F16R16) fasting for 48 hours (F48), and
fasting for 48 hours then refed for 24 hours (F48R24). At the end of the
diet, the genes were analyzed using DNA chips, and the expression of 7407
genes retained for all the chickens.  The data were then preprocessed in a standard manner for DNA chips (normalisation, eliminating the chip effect, etc.). The aim of the study is to see whether the genes are expressed differently
depending on the situation of stress. More precisely, it may be interesting to see how long the
chicken needs to be refed after fasting before it returns to a normal state, i.e.,
a state comparable to the state of a chicken with a normal diet. Might some
genes be underexpressed during fasting and overexpressed during feeding?
Data can be found at http://factominer.free.fr/book/chicken.csv


