---
title: "Assignment 1: proposition of answers"
output: 
  html_document: default
  bookdown::pdf_book:
    fig_caption: yes
    highlight: tango
    includes:
      before_body: before_body.tex
      in_header: header_lx_en.tex
    keep_tex: no
    number_sections: yes
    toc: yes
  pdf_document: default
geometry: top=2.4cm, bottom=2.1cm, outer=2cm, inner=4cm, headheight=40pt
lang: fr
documentclass: article
classoption: a4paper
---

<!-- 
Deux niveaux sont possibles dans ces exercices.
- Avancé : Les participants peuvent lire les fichiers originaux disponibles et en faire le nettoyage avant de pouvoir faire les jointures avec prenoms
  + `readr::read.csv2`, `readxl::read_excel`
  + `tidyr::gather`

- Intermédiaire : Les participants peuvent utiliser les fichiers déjà préparés
  + `filter`
  + `group_by`
  + `summarise`
  + `inner_join`
  + `summarise_if`
  + `mutate_at`
  
-->

```{r include = FALSE}
# remotes::install_github("statnmap/pdfreport")
knitr::opts_chunk$set(echo = TRUE)
```

## Warm-up

### Make sure you've installed {dplyr} >= 0.7 and {prenoms} package

```{r eval=FALSE, echo=FALSE}
install.packages("dplyr")
utils::packageDescription("dplyr", fields = "Version") # doit retourner au moins la 0.7
#install.packages("devtools")

remotes::install_github( "ThinkR-open/prenoms" )
# si l'install depuis github ne fonctionne pas :
# install.packages("prenoms_0.1.0.tar.gz",repos = NULL,type="source")
```

```{r, eval=FALSE, echo=FALSE}
# Preparation des data departement
# - Lecture donnees spatiales, calcul surface departement
# - Retire infos spatiales
dpt <- st_read(dsn = 'data/DEPARTEMENT', 
                    layer = 'DEPARTEMENT',
                    quiet = TRUE)
# Calcul surface
dpt_surf <- st_area(dpt) %>%
  units::drop_units()

# Combine avec nom dpt et regions
dpt_data_modif <- as.data.frame(dpt) %>%
  mutate(surface_m = dpt_surf) %>%
  dplyr::select(CODE_DEPT, NOM_DEPT, CODE_CHF, NOM_CHF, CODE_REG, NOM_REG,
         surface_m)

# Sauve pour utilisation en csv
write_csv(dpt_data_modif, "data/dpt_data_modif.csv")
```

### Load here `{dplyr}`, `{prenoms}` and any other needed package

```{r, message=FALSE}
library(dplyr)
library(tidyr)
library(prenoms)
library(readr)
library(readxl)
library(ggplot2)
library(sf)
```

### Import

#### prenomsdataset

Using `data(prenoms)` load `prenoms` dataset from  `{prenoms}` package.

```{r}
data(prenoms)
```

What kind of object is `prenoms` ? 

```{r}
class(prenoms)
```

Explore the database using the '5-functions-to-always-run-on-a-database'

```{r, eval=FALSE}
dim(prenoms)
names(prenoms)
head(prenoms)
View(prenoms)
summary(prenoms)
```

Using `glimpse`, have a look at `prenoms`'s structure.

```{r}
glimpse(prenoms)
```

#### Regions, departements and surfaces

Load the "dpt_data_modif.csv" dataset from IGN (French public state administrative establishment founded in 1940[1] to produce and maintain geographical information for France and its overseas departments and territories) using the appropriate function. Data have been prepared for you: the surface of departement has been calculated and spatial data removed.

```{r}
dpt_data_modif <- read_csv("data/dpt_data_modif.csv")
```


#### Elementary and college schools

We also fetched for you on [data.gouv.fr](https://www.data.gouv.fr/fr/datasets/adresse-et-geolocalisation-des-etablissements-denseignement-du-premier-et-second-degres/#_) the addresses of "primary and secondary schools, the administrative structures of the Ministry of National Education. Public and private sectors."

1. Data preprocessing 
    + Import the csv file : "DEPP-etab-1D2D.csv" and name it "depp_orig"
        + Encoding is `"latin1"`
    + Transform zip code ("code_postal_uai") into 5 characters with zeros
    + Extract department numbers ("dpt") starting from column "code_postal_uai"
    + Save the modifications into "depp_modif.csv"




```{r}
depp_orig <- read.csv2("data/DEPP-etab-1D2D.csv",
                       encoding = "latin1") 

depp_modif <- depp_orig %>%
  mutate(code_postal_uai = 
           formatC(code_postal_uai, width = 5, flag = "0")) %>%
  mutate(dpt = substr(code_postal_uai, 1,2))

write_csv(depp_modif, "data/depp_modif.csv")

```

2. Read the pre-processed "depp_modif.csv" file

```{r, warning=FALSE}
depp_modif <- read_csv("data/depp_modif.csv")
```


#### Facts observed by the police services and national gendarmerie units by department

We also gathered data from [data.gouv.fr](https://www.data.gouv.fr/fr/datasets/faits-constates-par-index-par-departement-et-par-annee/#_) concerning "all the facts observed by the police services and national gendarmerie units by department from 1996 to 2011"

1. Data preprocessing 
    - Import Excel sheet "2010" from "faitsconstatespardepartementde2002-a-2011.xls" file
        + _beware of the original formatting_
    - Copy it into "faits_2010_modif" in order to make some modifications:
        + Delete Excel calculations:
            + `Tout_département`, `Tout_index`
        + Transform in long format using `gather`
            + 4 columns : Index, Libellé, dpt, nombre
        + save the dataframe into a csv file "faits_2010_modif.csv"

```{r}
faits_2010_orig <- read_excel(
  "data/faitsconstatespardepartementde2002-a-2011.xls",
  sheet = "2010", skip = 2
)

# Supprimer les données issues de calculs dans Excel
faits_2010_modif <- faits_2010_orig[-1,-3] %>%
  gather(dpt, nombre, -Index, -Libellé)

write_csv(faits_2010_modif, "data/faits_2010_modif.csv")
  
```

2. Read preprocessed file "faits_2010_modif.csv"

```{r, warning=FALSE}
faits_2010_modif <- read_csv("data/faits_2010_modif.csv")
```


## Analyses

Some assumptions to do the exercise:

- every child born in a department stays into that department until the end of college
- every children between 11 and 14 years old is in a college
- the number of college is constant between 2010 and 2016
- College "à ouvrir" (i.e. "to be open") do not have children. Others have.


### Filter datasets to Metropolitan France

Datasets to be filtered: `prenoms`, `depp_modif`, `faits_2010_modif`, `dpt_data_modif`

- Department named "2A" and "2B" should be merged to "20"
- We only work with data in Metropolitan France, which means for "dpt" between `01` and `95` included. Others needs to be filtered.

```{r}
prenoms_metro <- prenoms %>% 
  mutate(dpt = if_else(dpt %in% c("2A", "2B"), "20", dpt)) %>% 
  filter(dpt %in% formatC(1:95, width = 2, flag = "0"))

depp_metro <- depp_modif %>% 
  mutate(dpt = if_else(dpt %in% c("2A", "2B"), "20", dpt)) %>% 
  filter(dpt %in% formatC(1:95, width = 2, flag = "0"))

faits_2010_metro <- faits_2010_modif %>% 
  mutate(dpt = if_else(dpt %in% c("2A", "2B"), "20", dpt)) %>% 
  filter(dpt %in% formatC(1:95, width = 2, flag = "0"))

dpt_data_metro <- dpt_data_modif %>% 
    mutate(CODE_DEPT = if_else(CODE_DEPT %in% c("2A", "2B"), "20", CODE_DEPT)) %>% 
  filter(CODE_DEPT %in% formatC(1:95, width = 2, flag = "0"))

dpt_data_metro
```



### National average number of children per college in 2010 ?

```{r}
# Enfants ayant 11 à 14 ans en 2010
nb_enfants <- prenoms_metro %>%
  filter(year >= 1996 & year <= 1999) %>%
  summarise(total = sum(n))

# Nombre de collèges en France en 2010 (=2016)
nb_colleges <- depp_metro %>%
  filter(nature_uai_libe == "Collège" &
           etat_etablissement) %>%
  nrow()

# Nombre d'enfants par collège au niveau national en 2010
nb_enfants/nb_colleges

```

### Average number of children per college in 2010 in each department?

- Arrange departments according to the calculated average in descending order

```{r}
# Enfants ayant 11 à 14 ans en 2016 par dpt
nb_enfants <- prenoms_metro %>%
  filter(year >= 1996 & year <= 1999) %>%
  group_by(dpt) %>%
  summarise(enf = sum(n))

# Nombre de collèges en France en 2016
nb_colleges <- depp_metro %>%
  filter(nature_uai_libe == "Collège") %>%
  group_by(dpt) %>%
  summarise(coll = n())

# Jointure
enf_coll <- inner_join(nb_enfants, nb_colleges, by = "dpt") %>%
  mutate(ratio = enf/coll) %>%
  arrange(desc(ratio))

enf_coll
```

### Number of Facts observed by the police services in 2010 per department ? 

```{r}
# Nb faits par dpt en 2010
faits_2010_metro %>%
  group_by(dpt) %>%
  summarise(faits = sum(nombre))
```

### Number of children born, number of colleges and facts related by the police services per department in 2010 ?

- Group all information in the same table
- Arrange by descending order of children, schools and facts

```{r}
# Enfants nés en 2010 par dpt
nb_enfants <- prenoms_metro %>%
  filter(year == 2010) %>%
  group_by(dpt) %>%
  summarise(nb_enfants = sum(n))

# Nombre de collèges en France en 2016
nb_colleges <- depp_metro %>%
  filter(nature_uai_libe == "Collège") %>%
  group_by(dpt) %>%
  summarise(nb_colleges = n())

# Nb faits par dpt en 2010
nb_faits <- faits_2010_metro %>%
  group_by(dpt) %>%
  summarise(nb_faits = sum(nombre))

# Jointure par dpt
all_by_dpt <- nb_enfants %>%
  inner_join(nb_colleges, by = "dpt") %>%
  inner_join(nb_faits, by = "dpt") %>%
  arrange(desc(nb_enfants), desc(nb_colleges), desc(nb_faits))

all_by_dpt
```

### Number of children born, number of colleges and facts related by the police services per km² in 2010 by department?
```{r, echo=FALSE, eval=FALSE}
# Pour avoir un jeu de données pour prenoms_dplyr
data_dplyr <- dpt_data_metro %>%
  inner_join(all_by_dpt, by = c("CODE_DEPT" = "dpt")) %>%
  select(CODE_DEPT, NOM_DEPT, surface_m:nb_faits)

write_csv(data_dplyr,
          "data/prenoms_dplyr_dept_colleges_faits.csv")
```


```{r}
stats_km2 <- dpt_data_modif %>%
  mutate(surface_km = surface_m / 1e6) %>%
  inner_join(all_by_dpt, by = c("CODE_DEPT" = "dpt")) %>%
  mutate_if(is.integer, as.numeric) %>% # facultatif
  mutate_at(vars(starts_with("nb_")), funs(bykm = ./surface_km))

stats_km2 %>% 
  select("CODE_DEPT", "NOM_DEPT", ends_with("bykm"), everything())
```

### Is there a correlation between the number of birth and the number of facts related by the police per km² in 2010 ?

```{r}
ggplot(stats_km2) +
  geom_point(aes(nb_enfants_bykm, nb_faits_bykm))

cor(stats_km2$nb_enfants_bykm, stats_km2$nb_faits_bykm, use = "pairwise.complete.obs")
```

**_Is this correlation value really interesting ? Think about the distribution of the data..._**

### What is the regional density (in number/km²) of the 15 most given first names in France ?

- Filter the 15 most given first names in France
- Create a unique wide table with the department as observations and the 15 most given names in columns (as variables): the count is at the row-column intersection 
- Merge with the surface department infos
- Compute the region surface and the density of names by region (e.g. number of people named "Bob", "Anna", ... by km² of each region)
    + Region name is stored in variable `NOM_REG`. (There are multiple departments in each region)

```{r}
# Top 15
top_prenoms <- prenoms %>%
  group_by(name) %>%
  summarise(total = sum(n)) %>%
  arrange(desc(total), name) %>%
  top_n(total, n = 15)

# Filter on top 15 and spread
top_spread <- prenoms %>%
  filter(name %in% pull(top_prenoms, name)) %>%
  group_by(dpt, name) %>%
  summarize(total = sum(n)) %>%
  spread(name, total)

# Join with surface in km2
top_dpt <- dpt_data_modif %>%
  mutate(surface_km = surface_m / 1e6) %>%
  inner_join(top_spread, by = c("CODE_DEPT" = "dpt"))

# Calculate Regional surface and total number by name
top_region <- top_dpt %>%
  group_by(NOM_REG) %>%
  summarise_if(is.numeric, sum)

# Calculate density
top_region_density <- top_region %>%
  mutate_at(vars(pull(top_prenoms, name)),
            funs(./surface_km))

top_region_density
```

#### Bonus question : map the mean regional density (in number/km²) of the 15 most given first names in France 

- Use the "department" shapefile to cross information and map data
    + Region name is stored in variable `NOM_REG`. (There are multiple departments in each region)
    + One map for each name

```{r}
region <- st_read(dsn = 'data/departements', 
                    layer = 'DEPARTEMENT',
                    quiet = TRUE) %>%
  group_by(NOM_REG) %>%
  summarise() %>%
  inner_join(top_region_density, by = "NOM_REG")

# One map for one name
ggplot(region) +
  aes(fill = Alain) +
  geom_sf() +
  coord_sf(crs = 2154) +
  scale_fill_gradient(low = "yellow", high = "purple")

# As facets for all names
region %>% 
  gather(key = "name", value = "density", Alain:René) %>% 
  ggplot() +
  aes(fill = density) +
  geom_sf() +
  coord_sf(crs = 2154) +
  scale_fill_gradient(low = "yellow", high = "purple") +
  facet_wrap(~name)
```

